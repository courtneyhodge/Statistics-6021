geom_point()
cor(life_data2$Life.expectancy, life_data2$GDP)
ggplot(life_data2, aes(x=GDP, y = Life.expectancy)) +
geom_point() +
geom_smooth(method = "lm", se = F)
beta_1 <- cor(life_data2$Life.expectancy, life_data2$GDP) * sd(life_data2$Life.expectancy) / sd(life_data2$GDP)
beta_0 <- mean(life_data2$Life.expectancy) - beta_1 * mean(life_data2$GDP)
beta_0
beta_1
model_1 <- lm(Life.expectancy~GDP, data = life_data2)
coef(model_1)
X <- cbind(1, life_data2$GDP)
Y <- as.matrix(life_data2$Life.expectancy)
beta_hat <- solve((t(X) %*% (X)))%*%t(X)%*%Y
beta_hat
library(tidyr)
Startups2 <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend, Profit)
Startups2 <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
Startups <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\Startups.csv")
library(tidyverse)
ggplot(Startups, aes(x=R.D.Spend, y = Profit)) +
geom_point() +
geom_smooth(method = "lm", se = F)
model_1 <- lm(Profit~R.D.Spend, data = Startups)
coef(model_1)
Bootstrap_estimates <- replicate(1000,{
bootstrap_samples <- Startups[sample(1:nrow(Startups), nrow(Startups), replace = T),]
#for each of the models, apply the linear models
boostrap_models <-lm(Profit~R.D.Spend, data = bootstrap_samples)
coef(boostrap_models)
})
Bootstrap_estimates
estimates <- data.frame(t(Bootstrap_estimates))
ggplot(Startups, aes(x=R.D.Spend, y = Profit)) +
geom_point() +
geom_smooth(method = "lm", se = F, color = 'red') +
geom_abline(data = estimates, aes(intercept = X.Intercept., slope = R.D.Spend), color = 'magenta')
summarize(estimates, mean_b0 = mean(X.Intercept.), mean_b1 = mean(R.D.Spend))
coef(model_1)
model_2 <- lm(Profit~R.D.Spend + Administration + Marketing.Spend, data = Startups)
coef(model_2)
X <- cbind(1, Startups$R.D.Spend, Startups$Administration, Startups$Marketing.Spend)
XtX <- t(X) %*%X
inverse_XtX <- solve(XtX)
Xty <- t(X)%*%Startups$Profit
beta <- inverse_XtX%*%Xty
library(tidyr)
Startups2 <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)]
Startups2 <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
long <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
long <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
ggplot(long, aes(x = value, y = Profit, color = predictor)) + geom_point() +
facet_wrap(~predictor, "free_x")
long <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
ggplot(long, aes(x = value, y = Profit, color = predictor)) + geom_point() +
facet_wrap(~predictor, nrom = "free_x")
long <- gather(Startups, key = "predictor", value = "value",
R.D.Spend, Administration, Marketing.Spend)
ggplot(long, aes(x = value, y = Profit, color = predictor)) + geom_point() +
facet_wrap(~predictor, scales = "free_x")
model1 <- lm(Profit~R.D.Spend + Administration + Marketing.Spend,
data = Startups)
model1 <- lm(Profit~R.D.Spend + Administration + Marketing.Spend,
data = Startups)
coef(model1)
Startups_pred <- mutate(Startups, predictions = fitted(model1),
resid = residuals(model1))
View(Startups_pred)
Startups_pred <- mutate(Startups, predictions = fitted(model1),
resid = residuals(model1))
ggplot(Startups_pred, aes(x = predictions, y = resid)) +
geom_point() + geom_hline(yintercept = 0, color = "orange")
ggplot(Startups_pred, aes(x = resid)) +
stat_qq() +
stat_qq_line()
ggplot(Startups_pred, aes(sample = resid)) +
stat_qq() +
stat_qq_line()
ggplot(Startups_pred, aes(sample = resid)) +
stat_qq() +
stat_qq_line( color = "yellow")
file.choose()
library(tidyverse)
data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
library(tidyverse)
data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data3<-select(life_data,Life.expectancy, Adult.Mortality,
infant.deaths,HIV.AIDS,BMI, GDP,Schooling)%>%
na.omit()
library(tidyverse)
life_data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data3<-select(life_data,Life.expectancy, Adult.Mortality,
infant.deaths,HIV.AIDS,BMI, GDP,Schooling)%>%
na.omit()
library(tidyverse)
life_data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data2<- select(life_data,Life.expectancy, GDP) |>
na.omit()
ggplot(life_data2, aes(x=GDP, y = Life.expectancy)) +
geom_point()
cor(life_data2$Life.expectancy, life_data2$GDP)
beta_1 <- cor(life_data2$Life.expectancy, life_data2$GDP) * sd(life_data2$Life.expectancy) / sd(life_data2$GDP)
beta_0 <- mean(life_data2$Life.expectancy) - beta_1 * mean(life_data2$GDP)
beta_0
beta_1
model_1 <- lm(Life.expectancy~GDP, data = life_data2)
coef(model_1)
X <- cbind(1, life_data2$GDP)
Y <- as.matrix(life_data2$Life.expectancy)
beta_hat <- solve((t(X) %*% (X)))%*%t(X)%*%Y
beta_hat
X <- cbind(1, life_data2$Adult.Mortality + infant.deaths + HIV.AIDS + BMI + GDP + Schooling)
X <- cbind(1, life_data3$Adult.Mortality + infant.deaths + HIV.AIDS + BMI + GDP + Schooling)
X <- cbind(1, life_data3$Adult.Mortality + life_data3$infant.deaths + life_data3$HIV.AIDS + life_data3$BMI + life_data3$GDP + life_data3$Schooling)
View(X)
life_data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data3<-select(life_data,Life.expectancy, Adult.Mortality,
infant.deaths,HIV.AIDS,BMI, GDP,Schooling)%>%
na.omit()
X <- cbind(1, life_data3$Adult.Mortality + life_data3$infant.deaths + life_data3$HIV.AIDS + life_data3$BMI + life_data3$GDP + life_data3$Schooling)
View(X)
X <- cbind(1, life_data3$Adult.Mortality, life_data3$infant.deaths, life_data3$HIV.AIDS, life_data3$BMI, life_data3$GDP,life_data3$Schooling)
View(X)
Y <- as.matrix(life_data3$Life.expectancy)
beta_hat <- solve((t(X) %*% (X)))%*%t(X)%*%Y
beta_hat
model <- lm(life.Expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling,
data = life_data3)
model <- lm(Life.Expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling,
data = life_data3)
model <- lm(Life.Expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling,
data = life_data3)
model <- lm(Life.expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling,
data = life_data3)
coef(model)
Bootstrap_estimates <- replicate(10000,{
bootstrap_samples <- life_data3[sample(1:nrow(life_data3), nrow(life_data3), replace = T),]
#for each of the models, apply the linear models
boostrap_models <-lm(Life.expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling, data = life_data3)
coef(boostrap_models)
})
Bootstrap_estimates
Bootstrap_estimates <- replicate(10000,{
bootstrap_samples <- life_data3[sample(1:nrow(life_data3), nrow(life_data3), replace = T),]
#for each of the models, apply the linear models
boostrap_models <-lm(Life.expectancy~Adult.Mortality +  infant.deaths + HIV.AIDS + BMI + GDP + Schooling, data = life_data3)
coef(boostrap_models)
})
Bootstrap_estimates <- replicate(1000,{
bootstrap_samples <- Startups[sample(1:nrow(Startups), nrow(Startups), replace = T),]
#for each of the models, apply the linear models
boostrap_models <-lm(Profit~R.D.Spend, data = bootstrap_samples)
coef(boostrap_models)
})
View(Bootstrap_estimates)
estimates <- data.frame(t(Bootstrap_estimates))
#summarize(estimates, mean_b0 = mean(X.Intercept.), mean_b1 = mean(R.D.Spend))
library(tidyverse)
life_data <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\expectancy.csv")
life_data2<- select(life_data,Life.expectancy, GDP) |>
na.omit()
ggplot(life_data2, aes(x=GDP, y = Life.expectancy)) +
geom_point()
cor(life_data2$Life.expectancy, life_data2$GDP)
beta_1 <- cor(life_data2$Life.expectancy, life_data2$GDP) * sd(life_data2$Life.expectancy) / sd(life_data2$GDP)
beta_0 <- mean(life_data2$Life.expectancy) - beta_1 * mean(life_data2$GDP)
beta_0
beta_1
model_1 <- lm(Life.expectancy~GDP, data = life_data2)
coef(model_1)
X <- cbind(1, life_data2$GDP)
Y <- as.matrix(life_data2$Life.expectancy)
beta_hat <- solve((t(X) %*% (X)))%*%t(X)%*%Y
beta_hat
estimates <- data.frame(t(Bootstrap_estimates))
estimates
file.choose()
planets <- read.csv("C:\\Users\\hodge\\OneDrive - Baylor University\\Desktop\\UVA Coding Folder\\STAT 6021\\PlanetsData.csv")
ggplot(planets, aes(x = distance, y = revolution)) +
geom_point()
Bootstrap_estimates <- replicate(1000,{
bootstrap_samples <- Startups[sample(1:nrow(Startups), nrow(Startups), replace = T),]
#for each of the models, apply the linear models
boostrap_models <-lm(Profit~R.D.Spend, data = bootstrap_samples)
coef(boostrap_models)
})
ggplot(planets, aes(x = distance, y = revolution)) +
geom_point() + geom_smooth(method = "lm", se = F)
model2 <- lm(revolution~distance, data = planets)
coef(model2)
planet_pred <- mutatue(planets, pred=fitted(model2), resid=residuals(model2))
planet_pred <- mutate(planets, pred=fitted(model2), resid=residuals(model2))
#residual plot
ggplot(planet_pred, aes(x=pred, y=resid)) +
geom_point() +
geom_hline(intercept = 0, color = "darkgoldenrod1")
#residual plot
ggplot(planet_pred, aes(x=pred, y=resid)) +
geom_point() +
geom_hline(yintercept = 0, color = "darkgoldenrod1")
ggplot(planets, aes(x = distance, y = revolution)) +
geom_point() + geom_smooth(method = "lm", se = F, color = "cornflowerblue")
ggplot(planets, aes(x = distance, y = revolution)) +
geom_point() + geom_smooth(method = "lm", se = F, color = "cyan")
ggplot(planet_pred, aes(sample = resid)) +
stat_qq() +
stat_qq_line()
planets2 <- mutate(planet, log_dist = log(distance), log_rev=log(revolution))
planets2 <- mutate(planets, log_dist = log(distance), log_rev=log(revolution))
ggplot(planets2, aes(x=log_dist, y=log_rev)) +
geom_point()
model3 <- lm(log_rev~log_dist, data=planets2)
coef(model3)
planet_pred2 <- mutate(planets2, pred=fitted(model3), resid=residuals(model3))
planet_pred2 <- mutate(planets2, pred=fitted(model3), resid=residuals(model3))
ggplot(planet_pred2, aes(x=pred, y=resid)) +
geom_point() +
geom_hline(yintercept = 0, color = 'brown1')
---
title: "7-26-24 Class"
#### Data !
n=100
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
x.seq=seq(min(x), max(x), 0.1)
#### Data !
n=100
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
y = b0 + b1*x + rnorm(n, mean=0, sd=6) #adds noise
plot(x, y, type="n")
points(x, y, col="black", pch=20)
mod.slr = lm(y ~ x)
lm(y~x)
coef(mod.slr)
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="black")
abline(lm(y~x),lty=2, lwd=2, col="red") #estimator model
n=100000
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
#x.seq=seq(min(x), max(x), 0.1)
y = b0 + b1*x + rnorm(n, mean=0, sd=6) #adds noise
#mean of zero above is an assumption
mod.slr = lm(y ~ x)
coef(mod.slr)
#### Plot
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="black") #true population line
abline(lm(y~x),lty=2, lwd=2, col="red") #estimator model
source("~/.active-rstudio-document", echo=TRUE)
n=100
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
#x.seq=seq(min(x), max(x), 0.1)
y = b0 + b1*x + rnorm(n, mean=0, sd=6) #adds noise
#mean of zero above is an assumption
mod.slr = lm(y ~ x)
coef(mod.slr)
#### Plot
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="black") #true population line
abline(lm(y~x),lty=2, lwd=2, col="red") #estimator model
n=1000
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
#x.seq=seq(min(x), max(x), 0.1)
y = b0 + b1*x + rnorm(n, mean=0, sd=6) #adds noise
#mean of zero above is an assumption
mod.slr = lm(y ~ x)
coef(mod.slr)
#### Plot
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="black") #true population line
abline(lm(y~x),lty=2, lwd=2, col="red") #estimator model
yhat = coef(mod.slr)[1] + coef(mod.slr)[2]*x
mse = sum((y-yhat)^2)/length(y)
find.mse = function(y, x, a, b){
yhat = a + b*x
mse = sum((y-yhat)^2)/length(y)
return(mse)
}
find.mse(y=y, x=x, a=coef(mod.slr)[1], b=coef(mod.slr)[2])
find.mse(y=y, x=x, a=coef(mod.slr)[1]+0.5, b=coef(mod.slr)[2]+0.5)
mse
find.mse(y=y, x=x, a=coef(mod.slr)[1], b=coef(mod.slr)[2])
a=seq( -20, 20, 1)
b=seq( -20, 20, 1)
a=seq( -20, 20, 1)
b=seq( -20, 20, 1)
#a=seq( -20, 20, 0.05)
#b=seq( -20, 20, 0.05)
## Find minimum
object.plain = matrix(NA, nrow=length(a), ncol=length(b))
object.ridge = matrix(NA, nrow=length(a), ncol=length(b))
object.lasso = matrix(NA, nrow=length(a), ncol=length(b))
for (i in 1:length(a)) {
for (j in 1:length(b)) {
object.plain[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j])
object.ridge[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2)
object.lasso[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(abs(a[i]) + abs(b[j]))
if((i %% 50==0) & (j==1)) {cat(paste0("iteration: ", i, "\n"))}
}
}
min(object.plain)
View(object.ridge)
View(object.plain)
min(object.plain)
soln.plain=which(object.plain == min(object.plain), arr.ind = TRUE)
soln.plain
a[soln.plain[1]] ; b[soln.plain[2]]
min(object.plain)
soln.plain=which(object.plain == min(object.plain), arr.ind = TRUE)
soln.plain
a[soln.plain[1]] ; b[soln.plain[2]]
View(object.plain)
object.plain = matrix(NA, nrow=length(a), ncol=length(b)) # a big ole matrix, where each row is a column is a slope
object.ridge = matrix(NA, nrow=length(a), ncol=length(b))
object.lasso = matrix(NA, nrow=length(a), ncol=length(b))
for (i in 1:length(a)) {
for (j in 1:length(b)) {
object.plain[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j])
object.ridge[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2)
object.lasso[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(abs(a[i]) + abs(b[j]))
if((i %% 50==0) & (j==1)) {cat(paste0("iteration: ", i, "\n"))}
}
}
## Standard
#object.plain
min(object.plain)
soln.plain=which(object.plain == min(object.plain), arr.ind = TRUE)
soln.plain
a[soln.plain[1]] ; b[soln.plain[2]]
## Ridge
#object.ridge
min(object.ridge)
soln.ridge=which(object.ridge == min(object.ridge), arr.ind = TRUE)
soln.ridge
a[soln.ridge[1]] ; b[soln.ridge[2]]
## Lasso
#object.lasso
min(object.lasso)
soln.lasso=which(object.lasso == min(object.lasso), arr.ind = TRUE)
soln.lasso
a[soln.lasso[1]] ; b[soln.lasso[2]]
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="red")
abline(lm(y~x),lty=2, lwd=2, col="black")
abline(a=a[soln.plain[1]],b=b[soln.plain[2]], lty=1, lwd=2, col="purple")
abline(a=a[soln.ridge[1]],b=b[soln.ridge[2]], lty=1, lwd=2, col="blue")
abline(a=a[soln.lasso[1]],b=b[soln.lasso[2]], lty=1, lwd=2, col="forestgreen")
#######################################################
## File:	Regex.R
## Purpose: Regression exploration
##
## Author: 	J. Blume
## Date:	July 26, 2025
#######################################################
#### Data !
n=1000
b0=5
b1=1
x = rnorm(n, mean=20 , sd=4)
#x.seq=seq(min(x), max(x), 0.1)
y = b0 + b1*x + rnorm(n, mean=0, sd=6) #adds noise
#mean of zero above is an assumption
mod.slr = lm(y ~ x)
coef(mod.slr)
#### Plot
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="black") #true population line
abline(lm(y~x),lty=2, lwd=2, col="red") #estimator model
#### Compute Mean Square Error
yhat = coef(mod.slr)[1] + coef(mod.slr)[2]*x
mse = sum((y-yhat)^2)/length(y)
find.mse = function(y, x, a, b){ #a and b are estimates
yhat = a + b*x
mse = sum((y-yhat)^2)/length(y)
return(mse)
}
find.mse(y=y, x=x, a=coef(mod.slr)[1], b=coef(mod.slr)[2])
find.mse(y=y, x=x, a=coef(mod.slr)[1]+0.5, b=coef(mod.slr)[2]+0.5)  #added a half to intercept and slope just because
## start simply
a=seq( -20, 20, 1) #yintercept
b=seq( -20, 20, 1) #slope
#a=seq( -20, 20, 0.05)
#b=seq( -20, 20, 0.05)
## Find minimum
object.plain = matrix(NA, nrow=length(a), ncol=length(b)) # a big ole matrix, where each row is a column is a slope
object.ridge = matrix(NA, nrow=length(a), ncol=length(b))
object.lasso = matrix(NA, nrow=length(a), ncol=length(b))
for (i in 1:length(a)) {
for (j in 1:length(b)) {
object.plain[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j])
object.ridge[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2)
object.lasso[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(abs(a[i]) + abs(b[j]))
if((i %% 50==0) & (j==1)) {cat(paste0("iteration: ", i, "\n"))}
}
}
## Standard
#object.plain
min(object.plain)
soln.plain=which(object.plain == min(object.plain), arr.ind = TRUE)
soln.plain
a[soln.plain[1]] ; b[soln.plain[2]]
## Ridge
#object.ridge
min(object.ridge)
soln.ridge=which(object.ridge == min(object.ridge), arr.ind = TRUE)
soln.ridge
a[soln.ridge[1]] ; b[soln.ridge[2]]
## Lasso
#object.lasso
min(object.lasso)
soln.lasso=which(object.lasso == min(object.lasso), arr.ind = TRUE)
soln.lasso
a[soln.lasso[1]] ; b[soln.lasso[2]]
#### Updated Plot
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="red")
abline(lm(y~x),lty=2, lwd=2, col="black")
abline(a=a[soln.plain[1]],b=b[soln.plain[2]], lty=1, lwd=2, col="purple") #plain old regression
abline(a=a[soln.ridge[1]],b=b[soln.ridge[2]], lty=1, lwd=2, col="blue") #ridge regression
abline(a=a[soln.lasso[1]],b=b[soln.lasso[2]], lty=1, lwd=2, col="forestgreen") #lasso regression
## Exercise -->
## Do this for Elastic Net!
## Keep the intercept; only shrink the slope.
## Draw the plots, and interpret. What do you see?
###
##
#
soln.plain
[soln.plain[1]]
soln.plain[1]
a[soln.plain[1]]
object.elasticnet = matrix(NA, nrow=length(a), ncol=length(b))
for (i in 1:length(a)) {
for (j in 1:length(b)) {
object.elasticnet[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2) + 0.2*(abs(a[i]) + abs(b[j]))
#object.ridge[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2)
#object.lasso[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(abs(a[i]) + abs(b[j]))
if((i %% 50==0) & (j==1)) {cat(paste0("iteration: ", i, "\n"))}
}
}
## Elasticnet
#object.elasticnet
min(object.elasticnet)
soln.elasticnet=which(object.elasticnet == min(object.elasticnet), arr.ind = TRUE)
soln.elasticnet
a[soln.elasticnet[1]] ; b[soln.elasticnet[2]]
View(object.elasticnet)
View(soln.elasticnet)
## Do this for Elastic Net!
## Keep the intercept; only shrink the slope.
## Draw the plots, and interpret. What do you see?
object.elasticnet = matrix(NA, nrow=length(a), ncol=length(b))
## Keep the intercept; only shrink the slope
for (i in 1:length(a)) {
for (j in 1:length(b)) {
object.elasticnet[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(b[j]^2) + 0.2*(abs(b[j]))
#object.ridge[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(a[i]^2 + b[j]^2)
#object.lasso[i,j] = find.mse(y=y, x=x, a=a[i], b=b[j]) + 0.2*(abs(a[i]) + abs(b[j]))
if((i %% 50==0) & (j==1)) {cat(paste0("iteration: ", i, "\n"))}
}
}
## Elasticnet
#object.elasticnet
min(object.elasticnet)
soln.elasticnet=which(object.elasticnet == min(object.elasticnet), arr.ind = TRUE)
soln.elasticnet
a[soln.elasticnet[1]] ; b[soln.elasticnet[2]]
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="red")
abline(lm(y~x),lty=2, lwd=2, col="black")
abline(a=a[soln.elasticnet[1]],b=b[soln.elasticnet[2]], lty=1, lwd=2, col="purple")
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="red")
abline(lm(y~x),lty=2, lwd=2, col="black")
plot(x, y, type="n")
points(x, y, col="black", pch=20)
abline(a=b0,b=b1,lty=1,lwd=2, col="red")
abline(lm(y~x),lty=2, lwd=2, col="black")
abline(a=a[soln.elasticnet[1]],b=b[soln.elasticnet[2]], lty=1, lwd=2, col="purple")
library(glmnet)
library(corrplot)
data(diabetes)
help(diabetes)
y <- diabetes$y ; length(y)
colnames(x)
setwd("C:/Users/hodge/Desktop/UVA_Coding_Folder/Statistics-6021")
